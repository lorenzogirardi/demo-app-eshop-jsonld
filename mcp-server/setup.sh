#!/bin/bash

echo "üöÄ Setting up E-commerce MCP Server with Multi-Provider AI Integration"

# Check if Node.js is installed
if ! command -v node &> /dev/null; then
    echo "‚ùå Node.js is not installed. Please install Node.js first."
    exit 1
fi

# Check if Docker is installed
if ! command -v docker &> /dev/null; then
    echo "‚ùå Docker is not installed. Please install Docker first."
    exit 1
fi

# Install dependencies
echo "üì¶ Installing dependencies..."
npm install

# Build the project
echo "üî® Building the project..."
npm run build

# Setup environment file
echo "‚öôÔ∏è  Setting up environment..."
if [ ! -f .env ]; then
    cp .env.example .env
    echo "üìù Created .env file. Please add your AI provider API keys."
fi

# Copy Prisma schema from parent directory if it exists
if [ -f ../prisma/schema.prisma ]; then
    echo "üìã Setting up Prisma..."
    mkdir -p prisma
    cp ../prisma/schema.prisma ./prisma/
    npx prisma generate
fi

# Start monitoring stack with Docker Compose
echo "üê≥ Starting monitoring stack (Prometheus, Grafana, Ollama)..."
docker-compose up -d

# Wait for services to be ready
echo "‚è≥ Waiting for services to start..."
sleep 30

# Pull Ollama models
echo "ü§ñ Setting up Ollama models..."
echo "   Pulling llama2..."
docker exec $(docker-compose ps -q ollama) ollama pull llama2 2>/dev/null || echo "   ‚ö†Ô∏è  Ollama not ready, you can pull models later with: docker exec <ollama-container> ollama pull llama2"

echo "   Pulling llama3..."
docker exec $(docker-compose ps -q ollama) ollama pull llama3 2>/dev/null || echo "   ‚ö†Ô∏è  You can pull llama3 later with: docker exec <ollama-container> ollama pull llama3"

echo ""
echo "‚úÖ Setup complete!"
echo ""
echo "üîó Access Points:"
echo "   - MCP Server Monitoring: http://localhost:9090"
echo "   - Prometheus: http://localhost:9091"
echo "   - Grafana: http://localhost:3001 (admin/admin)"
echo "   - Ollama API: http://localhost:11434"
echo ""
echo "ü§ñ AI Providers Supported:"
echo "   - OpenAI (ChatGPT): Add OPENAI_API_KEY to .env"
echo "   - Anthropic (Claude): Add ANTHROPIC_API_KEY to .env"
echo "   - Google (Gemini): Add GOOGLE_API_KEY to .env"
echo "   - Perplexity: Add PERPLEXITY_API_KEY to .env"
echo "   - Ollama (Local): Ready to use!"
echo ""
echo "üõ†Ô∏è  To start the MCP server:"
echo "   npm run dev"
echo ""
echo "üìä To test with Kiro IDE:"
echo "   1. The MCP configuration is already set in .kiro/settings/mcp.json"
echo "   2. Start the MCP server with 'npm run dev'"
echo "   3. Use tools like 'ai_chat', 'ai_analyze_products', etc."
echo ""
echo "üí° Example AI usage:"
echo "   - ai_chat with query: 'Analyze our top products'"
echo "   - ai_analyze_products with provider: 'openai', model: 'gpt-4'"
echo "   - ai_providers to see all available AI providers"